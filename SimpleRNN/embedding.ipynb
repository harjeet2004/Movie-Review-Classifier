{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06453d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b1c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentences\n",
    "sent=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bcfb7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c2935cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define vocabulary size\n",
    "\n",
    "voc_size=10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "872a1244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3937, 3714, 6083, 147],\n",
       " [3937, 3714, 6083, 5889],\n",
       " [3937, 7167, 6083, 9761],\n",
       " [1085, 5446, 9290, 5445, 7213],\n",
       " [1085, 5446, 9290, 5445, 5452],\n",
       " [2223, 3937, 9275, 6083, 7619],\n",
       " [4085, 8623, 4911, 5445]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## One-Hot representation\n",
    "\n",
    "one_hot_rep=[one_hot(words,voc_size) for words in sent]\n",
    "one_hot_rep\n",
    "\n",
    "## instead of a vector representaion with one place as 1 and rest all 0s based on the vocabulary, just represent as indexes where that particular word is 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d50528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## word embedding representation\n",
    "\n",
    "from tensorflow.keras.layers import Embedding \n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c5d3c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0, 3937, 3714, 6083,  147],\n",
       "       [   0,    0,    0,    0, 3937, 3714, 6083, 5889],\n",
       "       [   0,    0,    0,    0, 3937, 7167, 6083, 9761],\n",
       "       [   0,    0,    0, 1085, 5446, 9290, 5445, 7213],\n",
       "       [   0,    0,    0, 1085, 5446, 9290, 5445, 5452],\n",
       "       [   0,    0,    0, 2223, 3937, 9275, 6083, 7619],\n",
       "       [   0,    0,    0,    0, 4085, 8623, 4911, 5445]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "set_len=8 ## fixing the length of all sentences as number of inputs are fixed for all timestamps\n",
    "embedded_docs=pad_sequences(one_hot_rep,padding='pre',maxlen=set_len) ## pre-padding --> add zeros to the front of all sentences so that all have equal lengths for RNN processing\n",
    "embedded_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "977cc26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature representation\n",
    "dim=10  ## dim -- dimension -- number of features to be taken into acccount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5834d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,dim,input_length=set_len))\n",
    "model.build(input_shape=(None, set_len))\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0e58262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m10\u001b[0m)          │       \u001b[38;5;34m100,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> (390.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,000\u001b[0m (390.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> (390.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,000\u001b[0m (390.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032984a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Embedding Layer in RNN 🔹\n",
    "# - Like starting with a BLANK notebook filled with random scribbles.\n",
    "# - As the RNN trains on YOUR dataset (say movie review classification),\n",
    "#   the notebook gets rewritten so that useful words move closer together.\n",
    "#   Example: \"great\", \"awesome\", \"fantastic\" end up close in meaning.\n",
    "# - It only learns what helps YOUR task, so it’s very focused.\n",
    "# - Downside: it won’t understand broad language meanings outside your dataset.\n",
    "# - Analogy: Your personal exam notes → perfect for YOUR exam, but not for everyone else.\n",
    "\n",
    "# 🔹 CBOW Word2Vec 🔹\n",
    "# - Like a GIANT dictionary built from reading millions of books.\n",
    "# - Learns by predicting missing words from surrounding context\n",
    "#   (e.g., \"the cat ___ on the mat\" → \"sat\").\n",
    "# - Captures general word relationships:\n",
    "#   \"doctor\" ≈ \"nurse\", \"king - man + woman ≈ queen\".\n",
    "# - It’s general-purpose and reusable across many tasks.\n",
    "# - Analogy: Oxford Dictionary → not tied to your exam, but useful for many situations.\n",
    "\n",
    "# 🔹 Why the instructor did NOT use Word2Vec in the RNN 🔹\n",
    "# - The instructor wanted to show how an Embedding layer can learn from scratch\n",
    "#   directly on the given dataset.\n",
    "# - Word2Vec is PRETRAINED and requires extra steps:\n",
    "#   (download big embeddings, align vocab, load into Keras).\n",
    "# - For teaching/demo purposes, it’s simpler to just use Keras’ Embedding layer,\n",
    "#   which automatically learns task-specific embeddings during training.\n",
    "# - Also, if the dataset is large enough, the RNN’s own embeddings are often good enough,\n",
    "#   so there is no strict need to start with pretrained Word2Vec.\n",
    "\n",
    "# ✅ Both Embedding Layer and Word2Vec are based on the same core idea:\n",
    "# - Represent each word as a dense vector (instead of sparse one-hot).\n",
    "# - Have a big weight matrix of size (vocab_size × embedding_dim).\n",
    "# - Adjust that matrix during training so that words get meaningful vectors.\n",
    "\n",
    "# 🔹 BUT the difference lies in HOW and WHY they are trained:\n",
    "# - Word2Vec (CBOW/Skip-gram):\n",
    "#   → Trains ONLY to predict context words.\n",
    "#   → Goal = build a universal \"dictionary of meanings\".\n",
    "#   → Result = general-purpose embeddings (usable anywhere).\n",
    "#\n",
    "# - Embedding Layer inside RNN:\n",
    "#   → Trains along with the main task (e.g., sentiment classification).\n",
    "#   → Goal = adjust word vectors so they help minimize YOUR loss.\n",
    "#   → Result = task-specific embeddings (good for your dataset/task,\n",
    "#              may not generalize outside it).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96237926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.00782322, -0.01799371, -0.00418096, -0.04039834,\n",
       "          0.00074538,  0.0371852 , -0.01971728, -0.04057891,\n",
       "          0.03323558, -0.00467954],\n",
       "        [ 0.03180038,  0.01359086, -0.03352475, -0.02035583,\n",
       "         -0.01909379, -0.040486  ,  0.01094516, -0.03321411,\n",
       "         -0.03610901,  0.02524419],\n",
       "        [ 0.0035449 , -0.00838593,  0.02310022,  0.03722327,\n",
       "          0.02467633, -0.03871929, -0.03302045,  0.0261323 ,\n",
       "         -0.02788528,  0.03857759],\n",
       "        [-0.02203461, -0.0127776 , -0.03488387,  0.02245853,\n",
       "          0.0387342 ,  0.02118028,  0.02436442, -0.03510704,\n",
       "          0.04774598, -0.03654563]],\n",
       "\n",
       "       [[ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.00782322, -0.01799371, -0.00418096, -0.04039834,\n",
       "          0.00074538,  0.0371852 , -0.01971728, -0.04057891,\n",
       "          0.03323558, -0.00467954],\n",
       "        [ 0.03180038,  0.01359086, -0.03352475, -0.02035583,\n",
       "         -0.01909379, -0.040486  ,  0.01094516, -0.03321411,\n",
       "         -0.03610901,  0.02524419],\n",
       "        [ 0.0035449 , -0.00838593,  0.02310022,  0.03722327,\n",
       "          0.02467633, -0.03871929, -0.03302045,  0.0261323 ,\n",
       "         -0.02788528,  0.03857759],\n",
       "        [ 0.03883722, -0.02630684,  0.02826751, -0.04937265,\n",
       "          0.02200479, -0.02685457, -0.04103268,  0.04317688,\n",
       "          0.03343635,  0.03481999]],\n",
       "\n",
       "       [[ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.00782322, -0.01799371, -0.00418096, -0.04039834,\n",
       "          0.00074538,  0.0371852 , -0.01971728, -0.04057891,\n",
       "          0.03323558, -0.00467954],\n",
       "        [-0.01017932, -0.02560924,  0.04041678, -0.01385747,\n",
       "         -0.02602082,  0.00923958, -0.01279681,  0.00134134,\n",
       "         -0.0017602 , -0.01036439],\n",
       "        [ 0.0035449 , -0.00838593,  0.02310022,  0.03722327,\n",
       "          0.02467633, -0.03871929, -0.03302045,  0.0261323 ,\n",
       "         -0.02788528,  0.03857759],\n",
       "        [ 0.02014598, -0.02068621,  0.00722089, -0.02932179,\n",
       "         -0.02953556, -0.02791592, -0.01323241,  0.0260008 ,\n",
       "          0.02521216,  0.03451152]],\n",
       "\n",
       "       [[ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.03687258,  0.0225981 , -0.00882899, -0.03654933,\n",
       "         -0.00252663,  0.02888593,  0.01291341,  0.02761007,\n",
       "          0.0330542 , -0.01107237],\n",
       "        [-0.01345666,  0.00039502,  0.0269088 , -0.02389405,\n",
       "          0.04567728, -0.02595054,  0.02775068, -0.01132802,\n",
       "          0.0225911 , -0.04798596],\n",
       "        [ 0.0342391 ,  0.00670978, -0.03847547, -0.02234147,\n",
       "          0.01053496, -0.00208683, -0.04849821, -0.03256291,\n",
       "          0.02106914,  0.0103969 ],\n",
       "        [ 0.04236137,  0.02137821, -0.03119799, -0.02637937,\n",
       "         -0.03578512, -0.02378081,  0.01812691,  0.02104784,\n",
       "         -0.00788707,  0.01480447],\n",
       "        [-0.01655953, -0.04391355,  0.02163936, -0.01100162,\n",
       "          0.02084214,  0.03519327,  0.03818994, -0.02732084,\n",
       "         -0.00968057, -0.01901125]],\n",
       "\n",
       "       [[ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.03687258,  0.0225981 , -0.00882899, -0.03654933,\n",
       "         -0.00252663,  0.02888593,  0.01291341,  0.02761007,\n",
       "          0.0330542 , -0.01107237],\n",
       "        [-0.01345666,  0.00039502,  0.0269088 , -0.02389405,\n",
       "          0.04567728, -0.02595054,  0.02775068, -0.01132802,\n",
       "          0.0225911 , -0.04798596],\n",
       "        [ 0.0342391 ,  0.00670978, -0.03847547, -0.02234147,\n",
       "          0.01053496, -0.00208683, -0.04849821, -0.03256291,\n",
       "          0.02106914,  0.0103969 ],\n",
       "        [ 0.04236137,  0.02137821, -0.03119799, -0.02637937,\n",
       "         -0.03578512, -0.02378081,  0.01812691,  0.02104784,\n",
       "         -0.00788707,  0.01480447],\n",
       "        [ 0.01929741, -0.04217255, -0.01298189,  0.02985423,\n",
       "          0.00631313, -0.04638854,  0.0252156 ,  0.03438277,\n",
       "         -0.02148364,  0.00447502]],\n",
       "\n",
       "       [[ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01078893,  0.03089948,  0.02407832,  0.04548   ,\n",
       "         -0.03320024,  0.00476073, -0.02635989, -0.02539778,\n",
       "          0.04566479,  0.03336759],\n",
       "        [ 0.00782322, -0.01799371, -0.00418096, -0.04039834,\n",
       "          0.00074538,  0.0371852 , -0.01971728, -0.04057891,\n",
       "          0.03323558, -0.00467954],\n",
       "        [ 0.04162005, -0.00103774,  0.04031293,  0.02980555,\n",
       "         -0.00611637,  0.01756182,  0.04596659, -0.0494584 ,\n",
       "         -0.04543394,  0.01397225],\n",
       "        [ 0.0035449 , -0.00838593,  0.02310022,  0.03722327,\n",
       "          0.02467633, -0.03871929, -0.03302045,  0.0261323 ,\n",
       "         -0.02788528,  0.03857759],\n",
       "        [-0.04688882, -0.02578236, -0.01811252, -0.02646151,\n",
       "          0.01320608, -0.0459628 ,  0.02285396,  0.01886758,\n",
       "          0.04882308,  0.00360018]],\n",
       "\n",
       "       [[ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [ 0.01364317,  0.04685089, -0.01951307,  0.01807373,\n",
       "          0.02826028,  0.036609  , -0.02721768, -0.03781943,\n",
       "         -0.01946548,  0.03209307],\n",
       "        [-0.02824136,  0.01625352, -0.01685171,  0.02087453,\n",
       "         -0.01351488, -0.01152097, -0.03126468, -0.02971752,\n",
       "         -0.02716562,  0.02697328],\n",
       "        [ 0.00832026,  0.01421786,  0.00630288,  0.01958566,\n",
       "         -0.00767393,  0.0139891 , -0.00568987,  0.04760553,\n",
       "         -0.03394132,  0.03437283],\n",
       "        [-0.01201937, -0.01881537, -0.02815182, -0.03682632,\n",
       "          0.02346307,  0.02114259, -0.04890379,  0.03280933,\n",
       "         -0.01774283, -0.04989653],\n",
       "        [ 0.04236137,  0.02137821, -0.03119799, -0.02637937,\n",
       "         -0.03578512, -0.02378081,  0.01812691,  0.02104784,\n",
       "         -0.00788707,  0.01480447]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
